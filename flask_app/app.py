from flask import Flask, request, jsonify
from utils import search_articles, fetch_top_webpage_content, generate_answer
from langchain.memory import ConversationBufferMemory
from langchain.schema import HumanMessage, AIMessage

app = Flask(__name__)

# Initialize conversation memory
memory = ConversationBufferMemory(return_messages=True)

@app.route('/query', methods=['POST'])
def handle_query():
    data = request.json
    query = data.get('query')
    
    if not query:
        return jsonify({"error": "Query not provided"}), 400
    
    print(f"Received query: {query}")

    # Step 1: Search articles based on the query
    articles = search_articles(query)
    
    if articles is None:
        return jsonify({"error": "Failed to retrieve articles"}), 500
    
    print(f"Retrieved articles: {articles}")
    
    # Step 2: Fetch content from the top webpage
    if articles:
        top_article_url = articles[0].get('url')
        if top_article_url:
            full_text = fetch_top_webpage_content(query)
            print("Fetched Content: Generated by Serper ------------->")
            print(full_text)
        else:
            return jsonify({"error": "No valid URL found for the top article"}), 500
    else:
        return jsonify({"error": "No articles found"}), 500

    # Step 3: Generate answer using Claude with memory
    conversation_history = memory.chat_memory.messages
    prompt = f"""
    You are an AI assistant and should provide an accurate and contextual answer based on the following content, query, and conversation history.

    Content: {full_text}

    User Query: {query}

    Conversation History:
    {''.join([f"{msg.type}: {msg.content}\n" for msg in conversation_history])}

    Please provide a response that takes into account the conversation history and the current query.
    """
    
    # Display the prompt for debugging
    print("Prompt sent to Claude: --------------------->")
    print(prompt)
    
    answer = generate_answer(full_text, query, conversation_history)
    print("Generated by Claude: --------------------->", answer)

    # Step 4: Update memory with the new interaction
    memory.chat_memory.add_user_message(query)
    memory.chat_memory.add_ai_message(answer)

    # Step 5: Return the content and conversation history as JSON
    return jsonify({
        "content": answer,
        "prompt": prompt,
        "conversation": [
            {"role": "human" if isinstance(msg, HumanMessage) else "ai", "content": msg.content}
            for msg in memory.chat_memory.messages
        ]
    }), 200

if __name__ == '__main__':
    app.run(host='localhost', port=5001)
